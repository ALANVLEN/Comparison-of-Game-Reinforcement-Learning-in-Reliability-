{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "monitor_dir = r'./DraftRun_Logs/DR_Monitor'\n",
    "os.makedirs(monitor_dir,exist_ok=True)\n",
    "env = Monitor(env,monitor_dir)\n",
    "env = GrayScaleObservation(env,keep_dim=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "tensorboard_dir = r'./DraftRun_Logs/Tensorboard_Logs'\n",
    "model_param_1 = { 'buffer_size' : 1000, 'learning_rate' : 1e-3}\n",
    "model = DQN(\"CnnPolicy\", env, verbose=1,tensorboard_log = tensorboard_dir, **model_param_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_model_dir, verbose=1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = os.path.join(save_model_dir, 'best_model/')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "          print('self.n_calls:',self.n_calls)\n",
    "          model_path_1 = os.path.join(self.save_path, 'model_{}'.format(self.n_calls))\n",
    "          self.model.save(model_path_1)\n",
    "\n",
    "        return True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./DraftRun_Logs/Tensorboard_Logs\\DQN_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\openai\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.n_calls: 10000\n",
      "self.n_calls: 20000\n",
      "self.n_calls: 30000\n",
      "self.n_calls: 40000\n",
      "self.n_calls: 50000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.3e+04  |\n",
      "|    ep_rew_mean      | 990      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 277      |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 52018    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 504      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.9e+03  |\n",
      "|    ep_rew_mean      | 1.04e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 55174    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0814   |\n",
      "|    n_updates        | 1293     |\n",
      "----------------------------------\n",
      "self.n_calls: 60000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.31e+03 |\n",
      "|    ep_rew_mean      | 1.32e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 159      |\n",
      "|    time_elapsed     | 400      |\n",
      "|    total_timesteps  | 63727    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.088    |\n",
      "|    n_updates        | 3431     |\n",
      "----------------------------------\n",
      "self.n_calls: 70000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.39e+03 |\n",
      "|    ep_rew_mean      | 1.39e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 135      |\n",
      "|    time_elapsed     | 517      |\n",
      "|    total_timesteps  | 70179    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 5044     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.76e+03 |\n",
      "|    ep_rew_mean      | 1.4e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 607      |\n",
      "|    total_timesteps  | 75131    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0697   |\n",
      "|    n_updates        | 6282     |\n",
      "----------------------------------\n",
      "self.n_calls: 80000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.38e+03 |\n",
      "|    ep_rew_mean      | 1.37e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 113      |\n",
      "|    time_elapsed     | 717      |\n",
      "|    total_timesteps  | 81182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.089    |\n",
      "|    n_updates        | 7795     |\n",
      "----------------------------------\n",
      "self.n_calls: 90000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.23e+03 |\n",
      "|    ep_rew_mean      | 1.41e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 102      |\n",
      "|    time_elapsed     | 886      |\n",
      "|    total_timesteps  | 90475    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.237    |\n",
      "|    n_updates        | 10118    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.03e+03 |\n",
      "|    ep_rew_mean      | 1.39e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 96       |\n",
      "|    time_elapsed     | 1004     |\n",
      "|    total_timesteps  | 96974    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0842   |\n",
      "|    n_updates        | 11743    |\n",
      "----------------------------------\n",
      "self.n_calls: 100000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3e+03    |\n",
      "|    ep_rew_mean      | 1.41e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 89       |\n",
      "|    time_elapsed     | 1206     |\n",
      "|    total_timesteps  | 108107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 14526    |\n",
      "----------------------------------\n",
      "self.n_calls: 110000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.99e+03 |\n",
      "|    ep_rew_mean      | 1.45e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 84       |\n",
      "|    time_elapsed     | 1413     |\n",
      "|    total_timesteps  | 119493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 17373    |\n",
      "----------------------------------\n",
      "self.n_calls: 120000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.83e+03 |\n",
      "|    ep_rew_mean      | 1.49e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 82       |\n",
      "|    time_elapsed     | 1509     |\n",
      "|    total_timesteps  | 124734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 18683    |\n",
      "----------------------------------\n",
      "self.n_calls: 130000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.73e+03 |\n",
      "|    ep_rew_mean      | 1.51e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 80       |\n",
      "|    time_elapsed     | 1625     |\n",
      "|    total_timesteps  | 131142   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 20285    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.66e+03 |\n",
      "|    ep_rew_mean      | 1.53e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 1750     |\n",
      "|    total_timesteps  | 138100   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.423    |\n",
      "|    n_updates        | 22024    |\n",
      "----------------------------------\n",
      "self.n_calls: 140000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.55e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 1836     |\n",
      "|    total_timesteps  | 142732   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 23182    |\n",
      "----------------------------------\n",
      "self.n_calls: 150000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.52e+03 |\n",
      "|    ep_rew_mean      | 1.57e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 75       |\n",
      "|    time_elapsed     | 1994     |\n",
      "|    total_timesteps  | 151392   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 25347    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.46e+03 |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 74       |\n",
      "|    time_elapsed     | 2100     |\n",
      "|    total_timesteps  | 157255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 26813    |\n",
      "----------------------------------\n",
      "self.n_calls: 160000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.45e+03 |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 73       |\n",
      "|    time_elapsed     | 2275     |\n",
      "|    total_timesteps  | 166748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 29186    |\n",
      "----------------------------------\n",
      "self.n_calls: 170000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.39e+03 |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 2371     |\n",
      "|    total_timesteps  | 171964   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 30490    |\n",
      "----------------------------------\n",
      "self.n_calls: 180000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.39e+03 |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 2548     |\n",
      "|    total_timesteps  | 181666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0495   |\n",
      "|    n_updates        | 32916    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | 1.58e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 2688     |\n",
      "|    total_timesteps  | 189325   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 34831    |\n",
      "----------------------------------\n",
      "self.n_calls: 190000\n",
      "self.n_calls: 200000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.42e+03 |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 2937     |\n",
      "|    total_timesteps  | 202995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.227    |\n",
      "|    n_updates        | 38248    |\n",
      "----------------------------------\n",
      "self.n_calls: 210000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.44e+03 |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 3152     |\n",
      "|    total_timesteps  | 214763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 41190    |\n",
      "----------------------------------\n",
      "self.n_calls: 220000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.41e+03 |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 3285     |\n",
      "|    total_timesteps  | 221958   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.354    |\n",
      "|    n_updates        | 42989    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.36e+03 |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 3375     |\n",
      "|    total_timesteps  | 226896   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 44223    |\n",
      "----------------------------------\n",
      "self.n_calls: 230000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38e+03 |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 3586     |\n",
      "|    total_timesteps  | 238446   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.262    |\n",
      "|    n_updates        | 47111    |\n",
      "----------------------------------\n",
      "self.n_calls: 240000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 3739     |\n",
      "|    total_timesteps  | 246767   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.562    |\n",
      "|    n_updates        | 49191    |\n",
      "----------------------------------\n",
      "self.n_calls: 250000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 3898     |\n",
      "|    total_timesteps  | 255442   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.376    |\n",
      "|    n_updates        | 51360    |\n",
      "----------------------------------\n",
      "self.n_calls: 260000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 4026     |\n",
      "|    total_timesteps  | 262442   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.5      |\n",
      "|    n_updates        | 53110    |\n",
      "----------------------------------\n",
      "self.n_calls: 270000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 4230     |\n",
      "|    total_timesteps  | 273525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.307    |\n",
      "|    n_updates        | 55881    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 4334     |\n",
      "|    total_timesteps  | 279247   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 57311    |\n",
      "----------------------------------\n",
      "self.n_calls: 280000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 4407     |\n",
      "|    total_timesteps  | 283162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 58290    |\n",
      "----------------------------------\n",
      "self.n_calls: 290000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4535     |\n",
      "|    total_timesteps  | 290148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.738    |\n",
      "|    n_updates        | 60036    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4617     |\n",
      "|    total_timesteps  | 294644   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 61160    |\n",
      "----------------------------------\n",
      "self.n_calls: 300000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 1.71e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4822     |\n",
      "|    total_timesteps  | 305852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 63962    |\n",
      "----------------------------------\n",
      "self.n_calls: 310000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4915     |\n",
      "|    total_timesteps  | 310836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 65208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4967     |\n",
      "|    total_timesteps  | 313717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.714    |\n",
      "|    n_updates        | 65929    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 5080     |\n",
      "|    total_timesteps  | 319927   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.716    |\n",
      "|    n_updates        | 67481    |\n",
      "----------------------------------\n",
      "self.n_calls: 320000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 5158     |\n",
      "|    total_timesteps  | 324097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.13     |\n",
      "|    n_updates        | 68524    |\n",
      "----------------------------------\n",
      "self.n_calls: 330000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.87e+03 |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 5267     |\n",
      "|    total_timesteps  | 330017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.619    |\n",
      "|    n_updates        | 70004    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.85e+03 |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 5376     |\n",
      "|    total_timesteps  | 335977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 71494    |\n",
      "----------------------------------\n",
      "self.n_calls: 340000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.85e+03 |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 5482     |\n",
      "|    total_timesteps  | 341780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.724    |\n",
      "|    n_updates        | 72944    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 5598     |\n",
      "|    total_timesteps  | 348208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.578    |\n",
      "|    n_updates        | 74551    |\n",
      "----------------------------------\n",
      "self.n_calls: 350000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 5698     |\n",
      "|    total_timesteps  | 353618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.518    |\n",
      "|    n_updates        | 75904    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 5777     |\n",
      "|    total_timesteps  | 358060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.423    |\n",
      "|    n_updates        | 77014    |\n",
      "----------------------------------\n",
      "self.n_calls: 360000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 5989     |\n",
      "|    total_timesteps  | 369707   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 79926    |\n",
      "----------------------------------\n",
      "self.n_calls: 370000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | 1.57e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 6103     |\n",
      "|    total_timesteps  | 375915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 81478    |\n",
      "----------------------------------\n",
      "self.n_calls: 380000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 6204     |\n",
      "|    total_timesteps  | 381432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 82857    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | 1.53e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 6349     |\n",
      "|    total_timesteps  | 389499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.668    |\n",
      "|    n_updates        | 84874    |\n",
      "----------------------------------\n",
      "self.n_calls: 390000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 6469     |\n",
      "|    total_timesteps  | 396000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.586    |\n",
      "|    n_updates        | 86499    |\n",
      "----------------------------------\n",
      "self.n_calls: 400000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | 1.55e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 6598     |\n",
      "|    total_timesteps  | 402990   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.454    |\n",
      "|    n_updates        | 88247    |\n",
      "----------------------------------\n",
      "self.n_calls: 410000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.64e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 6735     |\n",
      "|    total_timesteps  | 410506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.741    |\n",
      "|    n_updates        | 90126    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.64e+03 |\n",
      "|    ep_rew_mean      | 1.55e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 6902     |\n",
      "|    total_timesteps  | 419765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 92441    |\n",
      "----------------------------------\n",
      "self.n_calls: 420000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7007     |\n",
      "|    total_timesteps  | 425525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.586    |\n",
      "|    n_updates        | 93881    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.55e+03 |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7055     |\n",
      "|    total_timesteps  | 428145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 94536    |\n",
      "----------------------------------\n",
      "self.n_calls: 430000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7213     |\n",
      "|    total_timesteps  | 436804   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.898    |\n",
      "|    n_updates        | 96700    |\n",
      "----------------------------------\n",
      "self.n_calls: 440000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.6e+03  |\n",
      "|    ep_rew_mean      | 1.53e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7327     |\n",
      "|    total_timesteps  | 443077   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.519    |\n",
      "|    n_updates        | 98269    |\n",
      "----------------------------------\n",
      "self.n_calls: 450000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | 1.53e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7478     |\n",
      "|    total_timesteps  | 451320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.414    |\n",
      "|    n_updates        | 100329   |\n",
      "----------------------------------\n",
      "self.n_calls: 460000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | 1.55e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7652     |\n",
      "|    total_timesteps  | 460810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.661    |\n",
      "|    n_updates        | 102702   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7776     |\n",
      "|    total_timesteps  | 467663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 104415   |\n",
      "----------------------------------\n",
      "self.n_calls: 470000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 7878     |\n",
      "|    total_timesteps  | 473188   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.644    |\n",
      "|    n_updates        | 105796   |\n",
      "----------------------------------\n",
      "self.n_calls: 480000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | 1.57e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 8013     |\n",
      "|    total_timesteps  | 480459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.92     |\n",
      "|    n_updates        | 107614   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | 1.58e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 8136     |\n",
      "|    total_timesteps  | 487185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.894    |\n",
      "|    n_updates        | 109296   |\n",
      "----------------------------------\n",
      "self.n_calls: 490000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 8261     |\n",
      "|    total_timesteps  | 493964   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.678    |\n",
      "|    n_updates        | 110990   |\n",
      "----------------------------------\n",
      "self.n_calls: 500000\n"
     ]
    }
   ],
   "source": [
    "save_model_dir_1 = r'./DraftRun_Logs/DraftRun_Bestmodel'\n",
    "callback_1 = SaveOnBestTrainingRewardCallback(check_freq = 10000, save_model_dir = save_model_dir_1)\n",
    "model.learn(total_timesteps = 500000, callback = callback_1)\n",
    "model.save(\"DraftRun_Mario_2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\openai\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n",
      "C:\\Users\\admin\\anaconda3\\envs\\openai\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-ead4cf743126>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0maction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_states\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdeterministic\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mobs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, actions)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \"\"\"\n\u001B[0;32m    161\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mactions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 162\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    164\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_images\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mSequence\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py\u001B[0m in \u001B[0;36mstep_wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     46\u001B[0m     ) -> Tuple[Union[np.ndarray, Dict[str, np.ndarray]], np.ndarray, np.ndarray, List[Dict[str, Any]],]:\n\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m         \u001B[0mobservations\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrewards\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdones\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfos\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvenv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[0mobservations\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfos\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstackedobs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobservations\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdones\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfos\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001B[0m in \u001B[0;36mstep_wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0menv_idx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_envs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001B[1;32m---> 44\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mactions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0menv_idx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m             )\n\u001B[0;32m     46\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuf_dones\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0menv_idx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\gym\\core.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 282\u001B[1;33m         \u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    283\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobservation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobservation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\stable_baselines3\\common\\monitor.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     88\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mneeds_reset\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Tried to step environment that needs reset\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 90\u001B[1;33m         \u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     91\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrewards\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreward\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     72\u001B[0m         \"\"\"\n\u001B[0;32m     73\u001B[0m         \u001B[1;31m# take the step and record the output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_action_map\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mreset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     16\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_max_episode_steps\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\nes_py\\nes_env.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    291\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontrollers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \u001B[1;31m# pass the action to the emulator as an unsigned byte\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 293\u001B[1;33m         \u001B[0m_LIB\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_env\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    294\u001B[0m         \u001B[1;31m# get the reward for this step\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m         \u001B[0mreward\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_reward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_dir = r'C:\\\\Users\\\\admin\\\\Desktop\\\\Mav\\\\Mario Code\\\\DraftRun_Logs\\DraftRun_Bestmodel\\\\best_model\\\\model_490000.zip'\n",
    "model = DQN.load(model_dir)\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}